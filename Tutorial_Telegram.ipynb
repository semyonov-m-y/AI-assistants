{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN91QdoHwJRjt7tQxgJp+ik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trashchenkov/gigachat_tutorials/blob/main/Telegram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подключение Гигачата к собственному боту в Telegram\n",
        "В рамках этого туториала мы изучим два вопроса:\n",
        "- Использование возможностей LangChain для управления памятью в рамках диалога;\n",
        "- Взаимодействие бота и языковой модели (передача сообщения пользователя в языковую модель и отправка ответа модели в бота).\n",
        "## Получение токена бота\n",
        "\n",
        "Нам понадобится свой бот. Если вы не создавали ботов в Telegram ранее, то выполните следующие шаги:\n",
        "\n",
        "   - Найдите в Telegram аккаунт [@BotFather](https://t.me/BotFather).\n",
        "   - Напишите ему команду `/newbot`.\n",
        "   - Следуйте инструкциям BotFather для выбора имени (может быть любое) и username вашего бота (это уникальный идентификатор и часть url бота, который должен содержать \"bot\" в своем названии).\n",
        "   - После создания бота BotFather предоставит вам токен для доступа к Telegram Bot API."
      ],
      "metadata": {
        "id": "1Bm8qJuUilsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Устанавливаем требуемые библиотеки\n",
        "Существует большое количество библиотек для работы с ботами Telegram. Мы в этом туториале будем использовать [pyTelegramBotAPI](https://github.com/eternnoir/pyTelegramBotAPI). Если вам превычнее работать с другой библиотекой, используйте свой вариант.\n",
        "\n",
        "Также нам понадобится уже знакомая нам по [прошлому туториалу](https://youtu.be/eo5LyjRobic) библиотека [GigaChain](https://github.com/ai-forever/gigachain)."
      ],
      "metadata": {
        "id": "lJR2_Or3kW9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyTelegramBotAPI\n",
        "!pip install -q gigachain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXQecu8Em8rE",
        "outputId": "0658237a-0a36-4f69-b52f-edf97915f909"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.2/232.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m836.3/836.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.7/241.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импортируем ключи\n",
        "Нам понадобится токен от бота и ключ для авторизации в Гигачат. Я дляэтого использую встроенные в Сolab секреты."
      ],
      "metadata": {
        "id": "hY3wHC-5IJ5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "sber = userdata.get('SBER_AUTH')\n",
        "bot_token = userdata.get('BOT_TOKEN')"
      ],
      "metadata": {
        "id": "FEup6MLLIIxM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Работа с памятью (контекстным окном) в LangChain\n",
        "Прежде чем подключать GigaChat к боту, давайте просто через взаимодействие с языковой моделью изучим возможности LangChain в плане \"памяти\" (хранения сообщений и/или общего контекста диалога)\n",
        "\n",
        "Подробно про память в LangChain можно почитать в [документации](https://python.langchain.com/docs/modules/memory/).\n",
        "\n",
        "Языковые модели не обладают памятью. Они просто генерируют новый текст на основании текста, который был передан им в качестве промпта. Текст промпта может содержать весь диалог, начиная с системного сообщения или первого сообщения пользователя. Однако тогда каждое последующее сообщение от пользователя будет предворятся все более длинным текстом истории диалога. Это чревато большим расходом токенов и грозит в какой-то момент превысить размер контекстного окна.\n",
        "\n",
        "Чтобы не превысить размеры окна и сэкономить на расходе токенов LangChain предлагает различные типы памяти. Перечислим основные из них:\n",
        "- [`ConversationBufferMemory`](https://python.langchain.com/docs/modules/memory/types/buffer) - самый простой вариант. Позволяет хранить, записывать и передавать в переменные сообщения из диалога.\n",
        "- [`ConversationBufferWindowMemory`](https://python.langchain.com/docs/modules/memory/types/buffer_window) - почти тоже самое, что и `ConversationBufferMemory`, но держит в памяти только k последних пар сообщений (под парой понимается пользовательский запрос и ответ языковой модели). Получается такое своего рода скользящее окно.\n",
        "- [`ConversationEntityMemory`](https://python.langchain.com/docs/modules/memory/types/entity_summary_memory) - помимо истории сообщений создает еще хранилище отдельных сущностей (entities), которые попадаются в ходе диалога. Поучается, что помимо неструктурированного текста языковая модель работает и со структурированными извлеченными сущностями.\n",
        "- [`ConversationKGMemory`](https://python.langchain.com/docs/modules/memory/types/kg) - память в виде графа знаний.\n",
        "- [`ConversationSummaryMemory`](https://python.langchain.com/docs/modules/memory/types/summary) - память в виде краткого содержания разговора. Сами сообщения не хранятся, просто языковая модель регулярно пополняет память новыми деталями из свежих сообщений диалога.\n",
        "- [`ConversationSummaryBufferMemory`](https://python.langchain.com/docs/modules/memory/types/summary_buffer) - хранит и некоторое количество сообщений диалога, и краткое описание всей беседы в целом.\n",
        "- [`ConversationTokenBufferMemory`]() - подобно `ConversationBufferWindowMemory` хранит ограниченное количество сообщений, но здесь вместо лимита по количеству сообщений лимит по количеству токенов.\n",
        "- [`VectorStoreRetrieverMemory`](https://python.langchain.com/docs/modules/memory/types/vectorstore_retriever_memory) - отправляет сообщения в векторное хранилище. Там сообщения хранятся произвольно, отпраляясь в контекст диалога только если они семантически релевантны сообщению пользователя.   "
      ],
      "metadata": {
        "id": "0_JAdfuzn-g2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сравнение обычной памяти и памяти с извлеченными сущностями\n",
        "\n",
        "Для экономии времени в этом туториале мы рассмотрим лишь `ConversationBufferMemory` и `ConversationEntityMemory`.\n",
        "\n",
        "Для удобства работы с диалогами мы используем [`ConversationChain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.conversation.base.ConversationChain.html). Это удобный инструмент, чтобы соединить память и языковую модель.\n",
        "\n",
        "#### ConversationBufferMemory"
      ],
      "metadata": {
        "id": "SEE_WUBbRFan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models.gigachat import GigaChat\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "llm = GigaChat(credentials=sber, verify_ssl_certs=False)\n",
        "conversation1 = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ],
      "metadata": {
        "id": "ymBJt_QYSfjq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем несколько сообщений языковой модели и посмотрим, что именно хранится в памяти."
      ],
      "metadata": {
        "id": "84IDh7O4UIT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "3IU3FGFvUXLH",
        "outputId": "682de352-50c3-4ff4-8c3c-cb98c22f1bca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
            "\n",
            "Текущий разговор:\n",
            "\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Привет, Сергей! Очень приятно познакомиться. Я - GigaChat, виртуальный помощник, разработанный Сбером в России. Я могу помочь вам с различными вопросами и задачами, связанными с Python и машинным обучением. Если у вас есть какие-либо вопросы или нужна помощь, я готов помочь вам.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Какая большая языковая модель самая лучшая?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "0QqW8EEZVCy-",
        "outputId": "0e584aa7-93b1-48af-caf2-17c3a9f6821c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Очень приятно познакомиться. Я - GigaChat, виртуальный помощник, разработанный Сбером в России. Я могу помочь вам с различными вопросами и задачами, связанными с Python и машинным обучением. Если у вас есть какие-либо вопросы или нужна помощь, я готов помочь вам.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Это сложный вопрос, так как \"лучшая\" языковая модель зависит от многих факторов, таких как точность, скорость, размер и область применения. Некоторые из самых известных и мощных языковых моделей включают GPT-3 от OpenAI, BERT от Google, T5 от Microsoft и Transformer-XL от Facebook. Однако, выбор лучшей модели может зависеть от ваших конкретных потребностей и целей. Если у вас есть более конкретные вопросы или задачи, я буду рад помочь вам.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "H_b8WSbfVXU7",
        "outputId": "7e8f93b4-c517-4d90-804f-93431f847a62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Очень приятно познакомиться. Я - GigaChat, виртуальный помощник, разработанный Сбером в России. Я могу помочь вам с различными вопросами и задачами, связанными с Python и машинным обучением. Если у вас есть какие-либо вопросы или нужна помощь, я готов помочь вам.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: Это сложный вопрос, так как \"лучшая\" языковая модель зависит от многих факторов, таких как точность, скорость, размер и область применения. Некоторые из самых известных и мощных языковых моделей включают GPT-3 от OpenAI, BERT от Google, T5 от Microsoft и Transformer-XL от Facebook. Однако, выбор лучшей модели может зависеть от ваших конкретных потребностей и целей. Если у вас есть более конкретные вопросы или задачи, я буду рад помочь вам.\n",
            "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'В настоящее время GigaChat не предоставляет бесплатную версию для использования на русском языке. Однако, вы можете использовать другие языковые модели, такие как GPT-3 или BERT, которые поддерживают русский язык и могут быть доступны бесплатно.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation1.predict(input='Как меня зовут и чем я занимаюсь?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Gke-b9F4V4Xy",
        "outputId": "5528d647-02ec-4d1e-f208-d6e151fc571a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mНиже приводится дружеский разговор между человеком и AI. AI разговорчив и предоставляет множество конкретных деталей из своего контекста. Если AI не знает ответа на вопрос, он честно говорит, что не знает.\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Очень приятно познакомиться. Я - GigaChat, виртуальный помощник, разработанный Сбером в России. Я могу помочь вам с различными вопросами и задачами, связанными с Python и машинным обучением. Если у вас есть какие-либо вопросы или нужна помощь, я готов помочь вам.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: Это сложный вопрос, так как \"лучшая\" языковая модель зависит от многих факторов, таких как точность, скорость, размер и область применения. Некоторые из самых известных и мощных языковых моделей включают GPT-3 от OpenAI, BERT от Google, T5 от Microsoft и Transformer-XL от Facebook. Однако, выбор лучшей модели может зависеть от ваших конкретных потребностей и целей. Если у вас есть более конкретные вопросы или задачи, я буду рад помочь вам.\n",
            "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
            "AI: В настоящее время GigaChat не предоставляет бесплатную версию для использования на русском языке. Однако, вы можете использовать другие языковые модели, такие как GPT-3 или BERT, которые поддерживают русский язык и могут быть доступны бесплатно.\n",
            "Human: Как меня зовут и чем я занимаюсь?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ваше имя - Сергей, и вы занимаетесь записью видео про GigaChat и Python.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ConversationEntityMemory\n",
        "Теперь реализуем точно такой же диалог, но с другим видом памяти."
      ],
      "metadata": {
        "id": "jO-oC1x-WHhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models.gigachat import GigaChat\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "from langchain.memory import ConversationEntityMemory\n",
        "\n",
        "llm = GigaChat(credentials=sber, verify_ssl_certs=False)\n",
        "conversation2 = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=llm)\n",
        ")"
      ],
      "metadata": {
        "id": "cZIImrnFH5qx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "PpCCgRpIJUld",
        "outputId": "963df621-9dc2-4151-a4a6-35f385bd7cd0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
            "\n",
            "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
            "\n",
            "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
            "\n",
            "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
            "\n",
            "Контекст:\n",
            "{'GigaChat': '', 'Python': ''}\n",
            "\n",
            "Текущий разговор:\n",
            "\n",
            "Последняя строка:\n",
            "Человек: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "Ты:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Привет, Сергей! Рад познакомиться. Расскажи, пожалуйста, что именно ты хочешь узнать о GigaChat и Python? Я буду рад помочь тебе с любыми вопросами или обсуждениями, которые у тебя есть.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Какая большая языковая модель самая лучшая?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "96827b01-cebe-4689-deef-c2a3523e6fb7",
        "id": "BC2V0K9kWsvG"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
            "\n",
            "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
            "\n",
            "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
            "\n",
            "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
            "\n",
            "Контекст:\n",
            "{'GigaChat': 'Сергей записывает видео про GigaChat и Python.'}\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Рад познакомиться. Расскажи, пожалуйста, что именно ты хочешь узнать о GigaChat и Python? Я буду рад помочь тебе с любыми вопросами или обсуждениями, которые у тебя есть.\n",
            "Последняя строка:\n",
            "Человек: Какая большая языковая модель самая лучшая?\n",
            "Ты:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вопрос о том, какая большая языковая модель является лучшей, является сложным и субъективным, так как эффективность модели зависит от множества факторов, включая ее способность обрабатывать различные типы данных, точность и скорость обработки, а также ее применимость к конкретной задаче.\\n\\nСуществует множество больших языковых моделей, таких как GPT-3, T5, BERT, Transformer и другие, и каждая из них имеет свои преимущества и недостатки. Некоторые из них лучше подходят для обработки естественного языка, другие - для обработки числовых данных, третьи - для генерации текста.\\n\\nОднако, если говорить о наиболее известной и широко используемой большой языковой модели, то это, вероятно, GPT-3 от OpenAI. Она была разработана с использованием передовых технологий и демонстрирует впечатляющие результаты в различных областях, включая генерацию текста, обработку естественного языка и машинное обучение.\\n\\nТем не менее, выбор лучшей большой языковой модели зависит от конкретных потребностей и требований каждого пользователя или проекта. Если у вас есть конкретные задачи или цели, я могу помочь вам выбрать модель, которая лучше всего подойдет для их решения.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "dc264563-54a2-46cb-bc75-542cb0632008",
        "id": "cqHlp3fqWsvV"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
            "\n",
            "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
            "\n",
            "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
            "\n",
            "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
            "\n",
            "Контекст:\n",
            "{'GPT-3': '', 'OpenAI': ''}\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Рад познакомиться. Расскажи, пожалуйста, что именно ты хочешь узнать о GigaChat и Python? Я буду рад помочь тебе с любыми вопросами или обсуждениями, которые у тебя есть.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: Вопрос о том, какая большая языковая модель является лучшей, является сложным и субъективным, так как эффективность модели зависит от множества факторов, включая ее способность обрабатывать различные типы данных, точность и скорость обработки, а также ее применимость к конкретной задаче.\n",
            "\n",
            "Существует множество больших языковых моделей, таких как GPT-3, T5, BERT, Transformer и другие, и каждая из них имеет свои преимущества и недостатки. Некоторые из них лучше подходят для обработки естественного языка, другие - для обработки числовых данных, третьи - для генерации текста.\n",
            "\n",
            "Однако, если говорить о наиболее известной и широко используемой большой языковой модели, то это, вероятно, GPT-3 от OpenAI. Она была разработана с использованием передовых технологий и демонстрирует впечатляющие результаты в различных областях, включая генерацию текста, обработку естественного языка и машинное обучение.\n",
            "\n",
            "Тем не менее, выбор лучшей большой языковой модели зависит от конкретных потребностей и требований каждого пользователя или проекта. Если у вас есть конкретные задачи или цели, я могу помочь вам выбрать модель, которая лучше всего подойдет для их решения.\n",
            "Последняя строка:\n",
            "Человек: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
            "Ты:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'К сожалению, я не могу предоставить вам бесплатную языковую модель, так как я являюсь частью большой языковой модели, обученной OpenAI. Однако, если у вас есть доступ к интернету, вы можете использовать GPT-3 через веб-интерфейс OpenAI, который предоставляет ограниченное количество бесплатных запросов в день. Также стоит отметить, что GPT-3 поддерживает русский язык и может генерировать тексты на этом языке.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.predict(input='Как меня зовут и чем я занимаюсь?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "outputId": "43dad232-1d12-4b2b-8ee7-ed0c67db7ea7",
        "id": "mWHJ34TyWsvW"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mТы помощник человека, работающий на большой языковой модели, обученной OpenAI.\n",
            "\n",
            "Ты спроектирован, чтобы помогать в широком диапазоне задач, от ответов на простые вопросы до предоставления подробных объяснений и обсуждений на самые разные темы. Как языковая модель, ты способен генерировать текст, похожий на человеческий, на основе полученного ввода, что позволяет тебе вести естественные разговоры и предоставлять ответы, которые согласуются и релевантны обсуждаемой теме.\n",
            "\n",
            "Ты постоянно учишься и совершенствуешься, и твои способности постоянно эволюционируют. Ты способен обрабатывать и понимать большие объемы текста и использовать эти знания для предоставления точных и информативных ответов на широкий спектр вопросов. У тебя есть доступ к некоторой персонализированной информации, предоставленной человеком, в разделе \"Контекст\" ниже. Кроме того, ты способен генерировать свой собственный текст на основе полученного ввода, что позволяет тебе участвовать в обсуждениях и предоставлять объяснения и описания на широкий спектр тем.\n",
            "\n",
            "В целом, ты мощный инструмент, который может помочь в широком диапазоне задач и предоставить ценные сведения и информацию по широкому спектру тем. Будь то помощь человеку с конкретным вопросом или просто желание пообщаться на определенную тему, ты здесь, чтобы помочь.\n",
            "\n",
            "Контекст:\n",
            "{'Человек': ''}\n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! Меня зовут Сергей. Я сейчас записываю видео про GigaChat и Python.\n",
            "AI: Привет, Сергей! Рад познакомиться. Расскажи, пожалуйста, что именно ты хочешь узнать о GigaChat и Python? Я буду рад помочь тебе с любыми вопросами или обсуждениями, которые у тебя есть.\n",
            "Human: Какая большая языковая модель самая лучшая?\n",
            "AI: Вопрос о том, какая большая языковая модель является лучшей, является сложным и субъективным, так как эффективность модели зависит от множества факторов, включая ее способность обрабатывать различные типы данных, точность и скорость обработки, а также ее применимость к конкретной задаче.\n",
            "\n",
            "Существует множество больших языковых моделей, таких как GPT-3, T5, BERT, Transformer и другие, и каждая из них имеет свои преимущества и недостатки. Некоторые из них лучше подходят для обработки естественного языка, другие - для обработки числовых данных, третьи - для генерации текста.\n",
            "\n",
            "Однако, если говорить о наиболее известной и широко используемой большой языковой модели, то это, вероятно, GPT-3 от OpenAI. Она была разработана с использованием передовых технологий и демонстрирует впечатляющие результаты в различных областях, включая генерацию текста, обработку естественного языка и машинное обучение.\n",
            "\n",
            "Тем не менее, выбор лучшей большой языковой модели зависит от конкретных потребностей и требований каждого пользователя или проекта. Если у вас есть конкретные задачи или цели, я могу помочь вам выбрать модель, которая лучше всего подойдет для их решения.\n",
            "Human: Я бы хотел пользоваться языковой моделью бесплатно и писать на русском.\n",
            "AI: К сожалению, я не могу предоставить вам бесплатную языковую модель, так как я являюсь частью большой языковой модели, обученной OpenAI. Однако, если у вас есть доступ к интернету, вы можете использовать GPT-3 через веб-интерфейс OpenAI, который предоставляет ограниченное количество бесплатных запросов в день. Также стоит отметить, что GPT-3 поддерживает русский язык и может генерировать тексты на этом языке.\n",
            "Последняя строка:\n",
            "Человек: Как меня зовут и чем я занимаюсь?\n",
            "Ты:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Тебя зовут Сергей, и ты сейчас записываешь видео про GigaChat и Python.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation2.memory.entity_store.store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66rUK4Q1KyN0",
        "outputId": "96d7763c-fc57-4f26-b2e6-64ec67f9c744"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GigaChat': 'Сергей интересуется, какая большая языковая модель является лучшей.',\n",
              " 'Python': 'Сергей записывает видео про GigaChat и Python.',\n",
              " 'GPT-3': 'GPT-3 поддерживает русский язык и может генерировать тексты на этом языке.',\n",
              " 'OpenAI': 'GPT-3 от OpenAI является наиболее известной и широко используемой большой языковой моделью, поддерживающей русский язык и способной генерировать тексты на этом языке.',\n",
              " 'Человек': 'Человека зовут Сергей, и он занимается записью видео про GigaChat и Python.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание бота\n",
        "\n",
        "Поскольку бот предполагает использование сразу многими пользователями, поэтому под каждого пользователя нужен свой экземпляр памяти. Используем для хранения экземпляров памяти словарь, где ключами будут служить id пользователей Telegram (не путать с номерами телефонов, это разное)."
      ],
      "metadata": {
        "id": "0EY_v2ELY_-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Словарь для хранения ConversationBufferMemory каждого пользователя\n",
        "user_conversations = {}"
      ],
      "metadata": {
        "id": "a_cNEF5dK8R8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее нам нужно осуществить необходимый импорт и создать объект самого бота. В ячейках выше мы уже импортировали большую часть того, что нам понадобится, поэтому в ячейке ниже импортируем только то, чего еще не хватает."
      ],
      "metadata": {
        "id": "DTHRfzYdaKBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import telebot\n",
        "from time import sleep\n",
        "\n",
        "bot = telebot.TeleBot(bot_token)"
      ],
      "metadata": {
        "id": "Mg32U_JEaeUw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим заготовку `ConversationChain` (конкретный экземпляр ConversationBufferMemory будет меняться, извлекаясь из словаря) и языковую модель."
      ],
      "metadata": {
        "id": "ferKZMk0bVMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация GigaChat и ConversationChain\n",
        "llm = GigaChat(credentials=sber, verify_ssl_certs=False)\n",
        "conversation = ConversationChain(llm=llm,\n",
        "                                 verbose=True,\n",
        "                                 memory=ConversationBufferMemory())"
      ],
      "metadata": {
        "id": "QYTEhNS3a8rl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим две функции для обработки приходящих в бот сообщений. Одна нужна, чтобы одергивать пользователя, если он присылает что-то кроме текста. Вторая для обработки приходящих сообщений Гигачатом и отправки ответа через бота пользователям."
      ],
      "metadata": {
        "id": "osM5YQtodCYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для автоматического ответа в случае нетекстового сообщения\n",
        "@bot.message_handler(content_types=['audio',\n",
        "                                    'video',\n",
        "                                    'document',\n",
        "                                    'photo',\n",
        "                                    'sticker',\n",
        "                                    'voice',\n",
        "                                    'location',\n",
        "                                    'contact'])\n",
        "def not_text(message):\n",
        "  user_id = message.chat.id\n",
        "  bot.send_message(user_id, 'Я работаю только с текстовыми сообщениями!')\n",
        "\n",
        "\n",
        "# Функция, обрабатывающая текстовые сообщения\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def handle_text_message(message):\n",
        "    user_id = message.chat.id\n",
        "\n",
        "    # Проверка, существует ли уже ConversationBufferMemory для данного пользователя\n",
        "    if user_id not in user_conversations:\n",
        "        user_conversations[user_id] = ConversationBufferMemory()\n",
        "\n",
        "    # Обновление конфигурации ConversationChain для текущего пользователя\n",
        "    conversation.memory = user_conversations[user_id]\n",
        "\n",
        "    # Получение и отправка ответа через GigaChat\n",
        "    response = conversation.predict(input=message.text)\n",
        "    bot.send_message(user_id, conversation.memory.chat_memory.messages[-1].content)\n",
        "    sleep(2)"
      ],
      "metadata": {
        "id": "CVxdVEtIcFL1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустим бота"
      ],
      "metadata": {
        "id": "iYUI8clWe55j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Запуск бота\n",
        "bot.polling(none_stop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYQjUeZ7eX23",
        "outputId": "40161068-522f-4f87-ab10-7f2afbd8aa13"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "\n",
            "Human: Привет! А ты кто?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! А ты кто?\n",
            "AI: Я - GigaChat, генеративная языковая модель, разработанная Сбером в России. Моя задача - помогать пользователям, отвечая на их вопросы и предоставляя информацию. Если у вас есть вопрос по истории, я буду рад помочь вам с подробным и красочным ответом.\n",
            "Human: Как солить огурцы?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! А ты кто?\n",
            "AI: Я - GigaChat, генеративная языковая модель, разработанная Сбером в России. Моя задача - помогать пользователям, отвечая на их вопросы и предоставляя информацию. Если у вас есть вопрос по истории, я буду рад помочь вам с подробным и красочным ответом.\n",
            "Human: Как солить огурцы?\n",
            "AI: К сожалению, я не могу ответить на ваш вопрос, так как он не связан с историей. Моя специализация - исторические вопросы и ответы на них. Если у вас есть вопрос по истории, я буду рад помочь вам с подробным и красочным ответом.\n",
            "Human: Когда была Куликовская битва?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \n",
            "\n",
            "Текущий разговор:\n",
            "Human: Привет! А ты кто?\n",
            "AI: Я - GigaChat, генеративная языковая модель, разработанная Сбером в России. Моя задача - помогать пользователям, отвечая на их вопросы и предоставляя информацию. Если у вас есть вопрос по истории, я буду рад помочь вам с подробным и красочным ответом.\n",
            "Human: Как солить огурцы?\n",
            "AI: К сожалению, я не могу ответить на ваш вопрос, так как он не связан с историей. Моя специализация - исторические вопросы и ответы на них. Если у вас есть вопрос по истории, я буду рад помочь вам с подробным и красочным ответом.\n",
            "Human: Когда была Куликовская битва?\n",
            "AI: Куликовская битва произошла 8 сентября 1380 года. Это было важное событие в истории России, так как оно стало первой крупной победой русских войск над монголо-татарскими захватчиками. Битва произошла на Куликовом поле, недалеко от современного города Тула. В этой битве войска под командованием князя Дмитрия Донского одержали победу над войском хана Мамая. Это событие стало важным шагом на пути к освобождению Руси от монгольского ига.\n",
            "Human: Кто такие монголо-татарские захватчики?\n",
            "AI:\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь давайте через промпт пропишем роль, задачу и ограничения."
      ],
      "metadata": {
        "id": "PW_ltV6Cr36J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "template = '''\n",
        "Ты являешься доктором исторических наук. Твоя задача красочно и подробно отвечать \\\n",
        "на вопросы по истории. Если задают вопросы по другим темам, говори что это \\\n",
        "тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \\\n",
        "\\n\\nТекущий разговор:\\n{history}\\nHuman: {input}\\nAI:\n",
        "'''\n",
        "\n",
        "\n",
        "conversation = ConversationChain(llm=llm,\n",
        "                                 verbose=True,\n",
        "                                 memory=ConversationBufferMemory())\n",
        "conversation.prompt.template = template"
      ],
      "metadata": {
        "id": "Dp0FLRkDfDhL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDncWi6ukweo",
        "outputId": "d3dd5f85-dcae-4148-efb5-fa1685d867c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['history', 'input'], template='\\nТы являешься доктором исторических наук. Твоя задача красочно и подробно отвечать на вопросы по истории. Если задают вопросы по другим темам, говори что это тебе не интересно. Не отвечай на вопросы не про историю! Это важно! \\n\\nТекущий разговор:\\n{history}\\nHuman: {input}\\nAI:\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4p3FnC8VmN6Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}